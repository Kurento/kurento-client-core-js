{
  "name": "core",
  "version": "6.15.0",
  "kurentoVersion": "6.15.0",
  "imports": [],
  "code": {
    "kmd": {
      "java": {
        "mavenGroupId": "org.kurento",
        "mavenArtifactId": "kms-api-core",
        "mavenVersion": "6.15.0"
      }
    },
    "api": {
      "java": {
        "packageName": "org.kurento.client",
        "mavenGroupId": "org.kurento",
        "mavenArtifactId": "kurento-client",
        "mavenVersion": "6.15.0"
      },
      "js": {
        "nodeName": "kurento-client-core",
        "npmDescription": "JavaScript Client API for Kurento Media Server",
        "npmGit": "Kurento/kurento-client-core-js",
        "npmVersion": "6.15.0"
      }
    },
    "implementation": {
      "cppNamespace": "kurento",
      "lib": "libkmscore"
    }
  },
  "remoteClasses": [
    {
      "name": "BaseRtpEndpoint",
      "doc": "Handles RTP communications.\n<p>\n  All endpoints that rely on the RTP protocol, like the\n  <strong>RtpEndpoint</strong> or the <strong>WebRtcEndpoint</strong>, inherit\n  from this class. The endpoint provides information about the connection state\n  and the media state, which can be consulted at any time through the\n  :rom:attr:`mediaState` and the :rom:attr:`connectionState` properties. It is\n  also possible subscribe to events fired when these properties change.\n</p>\n<ul>\n  <li>\n    <strong>ConnectionStateChangedEvent</strong>: This event is raised when the\n    connection between two peers changes. It can have two values:\n    <ul>\n      <li>CONNECTED</li>\n      <li>DISCONNECTED</li>\n    </ul>\n  </li>\n  <li>\n    <strong>MediaStateChangedEvent</strong>: This event provides information\n    about the state of the underlying RTP session.\n    <p>\n      The standard definition of RTP (<a\n        href='https://tools.ietf.org/html/rfc3550'\n        target='_blank'\n        >RFC 3550</a\n      >) describes a session as active whenever there is a maintained flow of\n      RTCP control packets, regardless of whether there is actual media flowing\n      through RTP data packets or not. The reasoning behind this is that, at any\n      given moment, a participant of an RTP session might temporarily stop\n      sending RTP data packets, but this wouldn't necessarily mean that the RTP\n      session as a whole is finished; it maybe just means that the participant\n      has some temporary issues but it will soon resume sending data. For this\n      reason, that an RTP session has really finished is something that is\n      considered only by the prolonged absence of RTCP control packets between\n      participants.\n    </p>\n    <p>\n      Since RTCP packets do not flow at a constant rate (for instance,\n      minimizing a browser window with a WebRTC's\n      <code>RTCPeerConnection</code> object might affect the sending interval),\n      it is not possible to immediately detect their absence and assume that the\n      RTP session has finished. Instead, there is a guard period of\n      approximately <strong>5 seconds</strong> of missing RTCP packets before\n      considering that the underlying RTP session is effectively finished, thus\n      triggering a <code>MediaStateChangedEvent = DISCONNECTED</code> event.\n    </p>\n    <p>\n      In other words, there is always a period during which there might be no\n      media flowing, but this event hasn't been fired yet. Nevertheless, this is\n      the most reliable and useful way of knowing what is the long-term, steady\n      state of RTP media exchange.\n    </p>\n    <p>\n      The <code>ConnectionStateChangedEvent</code> comes in contrast with more\n      instantaneous events such as MediaElement's\n      :rom:attr:`MediaFlowInStateChange` and\n      :rom:attr:`MediaFlowOutStateChange`, which are triggered almost\n      immediately after the RTP data packets stop flowing between RTP session\n      participants. This makes the <em>MediaFlow</em> events a good way to\n      know if participants are suffering from short-term intermittent\n      connectivity issues, but they are not enough to know if the connectivity\n      issues are just spurious network hiccups or are part of a more long-term\n      disconnection problem.\n    </p>\n    <p>\n      Possible values are:\n    </p>\n    <ul>\n      <li>CONNECTED: There is an RTCP packet flow between peers.</li>\n      <li>\n        DISCONNECTED: Either no RTCP packets have been received yet, or the\n        remote peer has ended the RTP session with a <code>BYE</code> message,\n        or at least 5 seconds have elapsed since the last RTCP packet was\n        received.\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>\n  Part of the bandwidth control for the video component of the media session is\n  done here:\n</p>\n<ul>\n  <li>\n    Input bandwidth: Configuration value used to inform remote peers about the\n    bitrate that can be pushed into this endpoint.\n    <ul>\n      <li>\n        <strong>{get,set}MinVideoRecvBandwidth</strong>: Minimum bitrate\n        requested on the received video stream.\n      </li>\n      <li>\n        <strong>{get,set}Max{Audio,Video}RecvBandwidth</strong>: Maximum bitrate\n        expected for the received stream.\n      </li>\n    </ul>\n  </li>\n  <li>\n    Output bandwidth: Configuration values used to control bitrate of the output\n    video stream sent to remote peers. It is important to keep in mind that\n    pushed bitrate depends on network and remote peer capabilities. Remote peers\n    can also announce bandwidth limitation in their SDPs (through the\n    <code>b={modifier}:{value}</code> tag). Kurento will always enforce bitrate\n    limitations specified by the remote peer over internal configurations.\n    <ul>\n      <li>\n        <strong>{get,set}MinVideoSendBandwidth</strong>: Minimum video bitrate\n        sent to remote peer.\n      </li>\n      <li>\n        <strong>{get,set}MaxVideoSendBandwidth</strong>: Maximum video bitrate\n        sent to remote peer.\n      </li>\n      <li>\n        <strong>RembParams.rembOnConnect</strong>: Initial local REMB bandwidth\n        estimation that gets propagated when a new endpoint is connected.\n      </li>\n    </ul>\n  </li>\n</ul>\n<p>\n  <strong>\n    All bandwidth control parameters must be changed before the SDP negotiation\n    takes place, and can't be changed afterwards.\n  </strong>\n</p>\n      ",
      "abstract": true,
      "extends": "SdpEndpoint",
      "properties": [
        {
          "name": "minVideoRecvBandwidth",
          "doc": "Minimum bitrate requested on the received video stream.\n<p>\n  This is used to set a minimum value of local REMB during bandwidth estimation,\n  if supported by the implementing class. The REMB estimation will then be sent\n  to remote peers, requesting them to send at least the indicated video bitrate.\n  It follows that min values will only have effect in remote peers that support\n  this congestion control mechanism, such as Chrome.\n</p>\n<ul>\n  <li>Unit: kbps (kilobits per second).</li>\n  <li>Default: 0.</li>\n  <li>\n    Note: The absolute minimum REMB value is 30 kbps, even if a lower value is\n    set here.\n  </li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "minVideoSendBandwidth",
          "doc": "Minimum video bitrate sent to remote peer.\n<p>\n  With this parameter you can control the minimum video quality that will be\n  sent when reacting to bad network conditions. Setting this parameter to a low\n  value permits the video quality to drop when the network conditions get worse.\n</p>\n<p>\n  This parameter provides a way to override the bitrate requested by remote REMB\n  bandwidth estimations: the bitrate sent will be always equal or greater than\n  this parameter, even if the remote peer requests even lower bitrates.\n</p>\n<p>\n  Note that if you set this parameter too high (trying to avoid bad video\n  quality altogether), you would be limiting the adaptation ability of the\n  congestion control algorithm, and your stream might be unable to ever recover\n  from adverse network conditions.\n</p>\n<ul>\n  <li>Unit: kbps (kilobits per second).</li>\n  <li>Default: 100.</li>\n  <li>\n    0 = unconstrained: the video bitrate will drop as needed, even to the\n    lowest possible quality, which might make the video completely blurry and\n    pixelated.\n  </li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "maxVideoSendBandwidth",
          "doc": "Maximum video bitrate sent to remote peer.\n<p>\n  With this parameter you can control the maximum video quality that will be\n  sent when reacting to good network conditions. Setting this parameter to a\n  high value permits the video quality to raise when the network conditions get\n  better.\n</p>\n<p>\n  This parameter provides a way to limit the bitrate requested by remote REMB\n  bandwidth estimations: the bitrate sent will be always equal or less than\n  this parameter, even if the remote peer requests higher bitrates.\n</p>\n<p>\n  Note that the default value of <strong>500 kbps</strong> is a VERY\n  conservative one, and leads to a low maximum video quality. Most applications\n  will probably want to increase this parameter to higher values such as 2000 (2\n  mbps) or even 10000 (10 mbps).\n</p>\n<p>\n  The REMB congestion control algorithm works by gradually increasing the output\n  video bitrate, until the available bandwidth is fully used or the maximum send\n  bitrate has been reached. This is a slow, progressive change, which starts at\n  300 kbps by default. You can change the default starting point of REMB\n  estimations, by setting <code>RembParams.rembOnConnect</code>.\n</p>\n<ul>\n  <li>Unit: kbps (kilobits per second).</li>\n  <li>Default: 500.</li>\n  <li>\n    0 = unconstrained: the video bitrate will grow until all the available\n    network bandwidth is used by the stream.<br />\n    Note that this might have a bad effect if more than one stream is running\n    (as all of them would try to raise the video bitrate indefinitely, until the\n    network gets saturated).\n  </li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "mediaState",
          "doc": "Media flow state.\n<ul>\n  <li>CONNECTED: There is an RTCP flow.</li>\n  <li>DISCONNECTED: No RTCP packets have been received for at least 5 sec.</li>\n</ul>\n          ",
          "type": "MediaState",
          "readOnly": true
        },
        {
          "name": "connectionState",
          "doc": "Connection state.\n<ul>\n  <li>CONNECTED</li>\n  <li>DISCONNECTED</li>\n</ul>\n          ",
          "type": "ConnectionState",
          "readOnly": true
        },
        {
          "name": "mtu",
          "doc": "Maximum Transmission Unit (MTU) used for RTP.\n<p>\n  This setting affects the maximum size that will be used by RTP payloads. You\n  can change it from the default, if you think that a different value would be\n  beneficial for the typical network settings of your application.\n</p>\n<p>\n  The default value is 1200 Bytes. This is the same as in <b>libwebrtc</b> (from\n  webrtc.org), as used by\n  <a\n    href='https://dxr.mozilla.org/mozilla-central/rev/b5c5ba07d3dbd0d07b66fa42a103f4df2c27d3a2/media/webrtc/trunk/webrtc/media/engine/constants.cc#16'\n    >Firefox</a\n  >\n  or\n  <a\n    href='https://codesearch.chromium.org/chromium/src/third_party/webrtc/media/engine/constants.cc?l=15&rcl=6dd488b2e55125644263e4837f1abd950d5e410d'\n    >Chrome</a\n  >\n  . You can read more about this value in\n  <a\n    href='https://groups.google.com/d/topic/discuss-webrtc/gH5ysR3SoZI/discussion'\n    >Why RTP max packet size is 1200 in WebRTC?</a\n  >\n  .\n</p>\n<p>\n  <b>WARNING</b>: Change this value ONLY if you really know what you are doing\n  and you have strong reasons to do so. Do NOT change this parameter just\n  because it <i>seems</i> to work better for some reduced scope tests. The\n  default value is a consensus chosen by people who have deep knowledge about\n  network optimization.\n</p>\n<ul>\n  <li>Unit: Bytes.</li>\n  <li>Default: 1200.</li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "rembParams",
          "doc": "Advanced parameters to configure the congestion control algorithm.",
          "type": "RembParams"
        }
      ],
      "events": [
        "MediaStateChanged",
        "ConnectionStateChanged"
      ]
    },
    {
      "name": "Endpoint",
      "doc": "Base interface for all end points.\n<p>\n  An Endpoint is a :rom:cls:`MediaElement` that allow :term:`KMS` to interchange\n  media contents with external systems, supporting different transport protocols\n  and mechanisms, such as :term:`RTP`, :term:`WebRTC`, :term:`HTTP`, ``file://``\n  URLs, etc.\n</p>\n<p>\n  An ``Endpoint`` may contain both sources and sinks for different media types,\n  to provide bidirectional communication.\n</p>\n      ",
      "abstract": true,
      "extends": "MediaElement"
    },
    {
      "name": "Filter",
      "doc": "Base interface for all filters.\n<p>\n  This is a certain type of :rom:cls:`MediaElement`, that processes media\n  injected through its sinks, and delivers the outcome through its sources.\n</p>\n      ",
      "abstract": true,
      "extends": "MediaElement"
    },
    {
      "name": "Hub",
      "doc": "A Hub is a routing :rom:cls:`MediaObject`.\nIt connects several :rom:cls:`endpoints <Endpoint>` together\n      ",
      "abstract": true,
      "extends": "MediaObject",
      "methods": [
        {
          "params": [
            {
              "name": "details",
              "doc": "Details of graph",
              "type": "GstreamerDotDetails",
              "optional": true
            }
          ],
          "return": {
            "type": "String",
            "doc": "The dot graph."
          },
          "name": "getGstreamerDot",
          "doc": "Returns a string in dot (graphviz) format that represents the gstreamer elements inside the pipeline"
        }
      ]
    },
    {
      "name": "HubPort",
      "doc": "This :rom:cls:`MediaElement` specifies a connection with a :rom:cls:`Hub`",
      "extends": "MediaElement",
      "constructor": {
        "params": [
          {
            "name": "hub",
            "doc": ":rom:cls:`Hub` to which this port belongs",
            "type": "Hub"
          }
        ],
        "doc": "Creates a :rom:cls:`HubPort` for the given :rom:cls:`Hub`"
      }
    },
    {
      "name": "MediaElement",
      "doc": "The basic building block of the media server, that can be interconnected inside a pipeline.\n<p>\n  A :rom:cls:`MediaElement` is a module that encapsulates a specific media\n  capability, and that is able to exchange media with other MediaElements\n  through an internal element called <b>pad</b>.\n</p>\n<p>\n  A pad can be defined as an input or output interface. Input pads are called\n  sinks, and it's where the media elements receive media from other media\n  elements. Output interfaces are called sources, and it's the pad used by the\n  media element to feed media to other media elements. There can be only one\n  sink pad per media element. On the other hand, the number of source pads is\n  unconstrained. This means that a certain media element can receive media only\n  from one element at a time, while it can send media to many others. Pads are\n  created on demand, when the connect method is invoked. When two media elements\n  are connected, one media pad is created for each type of media connected. For\n  example, if you connect AUDIO and VIDEO between two media elements, each one\n  will need to create two new pads: one for AUDIO and one for VIDEO.\n</p>\n<p>\n  When media elements are connected, it can be the case that the encoding\n  required in both input and output pads is not the same, and thus it needs to\n  be transcoded. This is something that is handled transparently by the\n  MediaElement internals, but such transcoding has a toll in the form of a\n  higher CPU load, so connecting MediaElements that need media encoded in\n  different formats is something to consider as a high load operation. The event\n  `MediaTranscodingStateChange` allows to inform the client application of\n  whether media transcoding is being enabled or not inside any MediaElement\n  object.\n</p>\n      ",
      "abstract": true,
      "extends": "MediaObject",
      "properties": [
        {
          "name": "minOuputBitrate",
          "doc": "Minimum video bandwidth for transcoding.\n@deprecated Deprecated due to a typo. Use :rom:meth:`minOutputBitrate` instead of this function.",
          "type": "int"
        },
        {
          "name": "minOutputBitrate",
          "doc": "Minimum video bitrate for transcoding.\n<ul>\n  <li>Unit: bps (bits per second).</li>\n  <li>Default: 0.</li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "maxOuputBitrate",
          "doc": "Maximum video bandwidth for transcoding.\n@deprecated Deprecated due to a typo. Use :rom:meth:`maxOutputBitrate` instead of this function.",
          "type": "int"
        },
        {
          "name": "maxOutputBitrate",
          "doc": "Maximum video bitrate for transcoding.\n<ul>\n  <li>Unit: bps (bits per second).</li>\n  <li>Default: MAXINT.</li>\n  <li>0 = unlimited.</li>\n</ul>\n          ",
          "type": "int"
        }
      ],
      "methods": [
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "return": {
            "type": "ElementConnectionData[]",
            "doc": "A list of the connections information that are sending media to this element. The list will be empty if no sources are found."
          },
          "name": "getSourceConnections",
          "doc": "Gets information about the sink pads of this media element.\n<p>\n  Since sink pads are the interface through which a media element gets it's\n  media, whatever is connected to an element's sink pad is formally a source of\n  media. Media can be filtered by type, or by the description given to the pad\n  though which both elements are connected.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO`, :rom:attr:`MediaType.VIDEO` or :rom:attr:`MediaType.DATA`",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "description",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "return": {
            "type": "ElementConnectionData[]",
            "doc": "A list of the connections information that are receiving media from this element. The list will be empty if no sources are found."
          },
          "name": "getSinkConnections",
          "doc": "Gets information about the source pads of this media element.\n<p>\n  Since source pads connect to other media element's sinks, this is formally the\n  sink of media from the element's perspective. Media can be filtered by type,\n  or by the description given to the pad though which both elements are\n  connected.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement` that will receive media",
              "type": "MediaElement"
            },
            {
              "name": "mediaType",
              "doc": "the :rom:enum:`MediaType` of the pads that will be connected",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "sourceMediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            },
            {
              "name": "sinkMediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "name": "connect",
          "doc": "Connects two elements, with the media flowing from left to right.\n<p>\n  The element that invokes the connect will be the source of media, creating one\n  sink pad for each type of media connected. The element given as parameter to\n  the method will be the sink, and it will create one sink pad per media type\n  connected.\n</p>\n<p>\n  If otherwise not specified, all types of media are connected by default\n  (AUDIO, VIDEO and DATA). It is recommended to connect the specific types of\n  media if not all of them will be used. For this purpose, the connect method\n  can be invoked more than once on the same two elements, but with different\n  media types.\n</p>\n<p>\n  The connection is unidirectional. If a bidirectional connection is desired,\n  the position of the media elements must be inverted. For instance,\n  webrtc1.connect(webrtc2) is connecting webrtc1 as source of webrtc2. In order\n  to create a WebRTC one-2one conversation, the user would need to specify the\n  connection on the other direction with webrtc2.connect(webrtc1).\n</p>\n<p>\n  Even though one media element can have one sink pad per type of media, only\n  one media element can be connected to another at a given time. If a media\n  element is connected to another, the former will become the source of the sink\n  media element, regardless whether there was another element connected or not.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "sink",
              "doc": "the target :rom:cls:`MediaElement` that will stop receiving media",
              "type": "MediaElement"
            },
            {
              "name": "mediaType",
              "doc": "the :rom:enum:`MediaType` of the pads that will be connected",
              "type": "MediaType",
              "optional": true
            },
            {
              "name": "sourceMediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            },
            {
              "name": "sinkMediaDescription",
              "doc": "A textual description of the media source. Currently not used, aimed mainly for :rom:attr:`MediaType.DATA` sources",
              "type": "String",
              "optional": true
            }
          ],
          "name": "disconnect",
          "doc": "Disconnects two media elements. This will release the source pads of the source media element, and the sink pads of the sink media element."
        },
        {
          "params": [
            {
              "name": "caps",
              "doc": "The format for the stream of audio",
              "type": "AudioCaps"
            }
          ],
          "name": "setAudioFormat",
          "doc": "Set the type of data for the audio stream.\n<p>\n  MediaElements that do not support configuration of audio capabilities will\n  throw a MEDIA_OBJECT_ILLEGAL_PARAM_ERROR exception.\n</p>\n<p>\n  NOTE: This method is not implemented yet by the Media Server to do anything\n  useful.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "caps",
              "doc": "The format for the stream of video",
              "type": "VideoCaps"
            }
          ],
          "name": "setVideoFormat",
          "doc": "Set the type of data for the video stream.\n<p>\n  MediaElements that do not support configuration of video capabilities will\n  throw a MEDIA_OBJECT_ILLEGAL_PARAM_ERROR exception\n</p>\n<p>\n  NOTE: This method is not implemented yet by the Media Server to do anything\n  useful.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "details",
              "doc": "Details of graph",
              "type": "GstreamerDotDetails",
              "optional": true
            }
          ],
          "return": {
            "type": "String",
            "doc": "The dot graph."
          },
          "name": "getGstreamerDot",
          "doc": "Return a .dot file describing the topology of the media element.\n<p>The element can be queried for certain type of data:</p>\n<ul>\n  <li>SHOW_ALL: default value</li>\n  <li>SHOW_CAPS_DETAILS</li>\n  <li>SHOW_FULL_PARAMS</li>\n  <li>SHOW_MEDIA_TYPE</li>\n  <li>SHOW_NON_DEFAULT_PARAMS</li>\n  <li>SHOW_STATES</li>\n  <li>SHOW_VERBOSE</li>\n</ul>\n          "
        },
        {
          "params": [
            {
              "name": "bitrate",
              "doc": "Configure the enconding media bitrate in bps",
              "type": "int"
            }
          ],
          "name": "setOutputBitrate",
          "doc": "@deprecated\nAllows change the target bitrate for the media output, if the media is encoded using VP8 or H264. This method only works if it is called before the media starts to flow."
        },
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO` or :rom:attr:`MediaType.VIDEO`",
              "type": "MediaType",
              "optional": true
            }
          ],
          "return": {
            "type": "Stats<>",
            "doc": "Delivers a successful result in the form of a RTC stats report. A RTC stats report represents a map between strings, identifying the inspected objects (RTCStats.id), and their corresponding RTCStats objects."
          },
          "name": "getStats",
          "doc": "Gets the statistics related to an endpoint. If no media type is specified, it returns statistics for all available types."
        },
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO` or :rom:attr:`MediaType.VIDEO`",
              "type": "MediaType"
            },
            {
              "name": "sinkMediaDescription",
              "doc": "Description of the sink",
              "type": "String",
              "optional": true,
              "defaultValue": "default"
            }
          ],
          "return": {
            "type": "boolean",
            "doc": "TRUE if there is media, FALSE in other case."
          },
          "name": "isMediaFlowingIn",
          "doc": "This method indicates whether the media element is receiving media of a certain type. The media sink pad can be identified individually, if needed. It is only supported for AUDIO and VIDEO types, raising a MEDIA_OBJECT_ILLEGAL_PARAM_ERROR otherwise. If the pad indicated does not exist, if will return false."
        },
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO` or :rom:attr:`MediaType.VIDEO`",
              "type": "MediaType"
            },
            {
              "name": "sourceMediaDescription",
              "doc": "Description of the source",
              "type": "String",
              "optional": true,
              "defaultValue": "default"
            }
          ],
          "return": {
            "type": "boolean",
            "doc": "TRUE if there is media, FALSE in other case."
          },
          "name": "isMediaFlowingOut",
          "doc": "This method indicates whether the media element is emitting media of a certain type. The media source pad can be identified individually, if needed. It is only supported for AUDIO and VIDEO types, raising a MEDIA_OBJECT_ILLEGAL_PARAM_ERROR otherwise. If the pad indicated does not exist, if will return false."
        },
        {
          "params": [
            {
              "name": "mediaType",
              "doc": "One of :rom:attr:`MediaType.AUDIO` or :rom:attr:`MediaType.VIDEO`",
              "type": "MediaType"
            },
            {
              "name": "binName",
              "doc": "Internal name of the processing bin, as previously given by ``MediaTranscodingStateChange``.",
              "type": "String",
              "optional": true,
              "defaultValue": "default"
            }
          ],
          "return": {
            "type": "boolean",
            "doc": "TRUE if media is being transcoded, FALSE otherwise."
          },
          "name": "isMediaTranscoding",
          "doc": "Indicates whether this media element is actively transcoding between input and output pads. This operation is only supported for AUDIO and VIDEO media types, raising a MEDIA_OBJECT_ILLEGAL_PARAM_ERROR otherwise.\n          The internal GStreamer processing bin can be indicated, if needed; if the bin doesn't exist, the return value will be FALSE."
        }
      ],
      "events": [
        "ElementConnected",
        "ElementDisconnected",
        "MediaFlowOutStateChange",
        "MediaFlowInStateChange",
        "MediaTranscodingStateChange"
      ]
    },
    {
      "name": "MediaObject",
      "doc": "Base interface used to manage capabilities common to all Kurento elements.\n<h4>Properties</h4>\n<ul>\n  <li>\n    <b>id</b>: unique identifier assigned to this <code>MediaObject</code> at\n    instantiation time. :rom:cls:`MediaPipeline` IDs are generated with a GUID\n    followed by suffix <code>_kurento.MediaPipeline</code>.\n    :rom:cls:`MediaElement` IDs are also a GUID with suffix\n    <code>_kurento.{ElementType}</code> and prefixed by parent's ID.\n    <blockquote>\n      <dl>\n        <dt><i>MediaPipeline ID example</i></dt>\n        <dd>\n          <code>\n            907cac3a-809a-4bbe-a93e-ae7e944c5cae_kurento.MediaPipeline\n          </code>\n        </dd>\n        <dt><i>MediaElement ID example</i></dt>\n        <dd>\n          <code>\n            907cac3a-809a-4bbe-a93e-ae7e944c5cae_kurento.MediaPipeline/403da25a-805b-4cf1-8c55-f190588e6c9b_kurento.WebRtcEndpoint\n          </code>\n        </dd>\n      </dl>\n    </blockquote>\n  </li>\n  <li>\n    <b>name</b>: free text intended to provide a friendly name for this\n    <code>MediaObject</code>. Its default value is the same as the ID.\n  </li>\n  <li>\n    <b>tags</b>: key-value pairs intended for applications to associate metadata\n    to this <code>MediaObject</code> instance.\n  </li>\n</ul>\n<p></p>\n<h4>Events</h4>\n<ul>\n  <li>\n    <b>ErrorEvent</b>: reports asynchronous error events. It is recommended to\n    always subscribe a listener to this event, as regular error from the\n    pipeline will be notified through it, instead of through an exception when\n    invoking a method.\n  </li>\n</ul>\n      ",
      "abstract": true,
      "properties": [
        {
          "name": "mediaPipeline",
          "doc": ":rom:cls:`MediaPipeline` to which this <code>MediaObject</code> belongs. It returns itself when invoked for a pipeline object.",
          "type": "MediaPipeline",
          "final": true
        },
        {
          "name": "parent",
          "doc": "Parent of this <code>MediaObject</code>.\n<p>\n  The parent of a :rom:cls:`Hub` or a :rom:cls:`MediaElement` is its\n  :rom:cls:`MediaPipeline`. A :rom:cls:`MediaPipeline` has no parent, so this\n  property will be null.\n</p>\n          ",
          "type": "MediaObject",
          "final": true
        },
        {
          "name": "id",
          "doc": "Unique identifier of this <code>MediaObject</code>.\n<p>\n  It's a synthetic identifier composed by a GUID and\n  <code>MediaObject</code> type. The ID is prefixed with the parent ID when the\n  object has parent: <i>ID_parent/ID_media-object</i>.\n</p>\n          ",
          "type": "String",
          "final": true
        },
        {
          "name": "childs",
          "doc": "Children of this <code>MediaObject</code>.\n@deprecated Use children instead.\n          ",
          "type": "MediaObject[]",
          "readOnly": true
        },
        {
          "name": "children",
          "doc": "Children of this <code>MediaObject</code>.",
          "type": "MediaObject[]",
          "readOnly": true
        },
        {
          "name": "name",
          "doc": "This <code>MediaObject</code>'s name.\n<p>\n  This is just sugar to simplify developers' life debugging, it is not used\n  internally for indexing nor identifying the objects. By default, it's the\n  object's ID.\n</p>\n          ",
          "type": "String"
        },
        {
          "name": "sendTagsInEvents",
          "doc": "Flag activating or deactivating sending the element's tags in fired events.",
          "type": "boolean"
        },
        {
          "name": "creationTime",
          "doc": "<code>MediaObject</code> creation time in seconds since Epoch.",
          "type": "int",
          "final": true
        }
      ],
      "methods": [
        {
          "params": [
            {
              "name": "key",
              "doc": "Tag name.",
              "type": "String"
            },
            {
              "name": "value",
              "doc": "Value associated to this tag.",
              "type": "String"
            }
          ],
          "name": "addTag",
          "doc": "Adds a new tag to this <code>MediaObject</code>.\nIf the tag is already present, it changes the value.\n          "
        },
        {
          "params": [
            {
              "name": "key",
              "doc": "Tag name to be removed",
              "type": "String"
            }
          ],
          "name": "removeTag",
          "doc": "Removes an existing tag.\nExists silently with no error if tag is not defined.\n          "
        },
        {
          "params": [
            {
              "name": "key",
              "doc": "Tag key.",
              "type": "String"
            }
          ],
          "return": {
            "type": "String",
            "doc": "The value associated to the given key."
          },
          "name": "getTag",
          "doc": "Returns the value of given tag, or MEDIA_OBJECT_TAG_KEY_NOT_FOUND if tag is not defined."
        },
        {
          "params": [],
          "return": {
            "type": "Tag[]",
            "doc": "An array containing all key-value pairs associated with this <code>MediaObject</code>."
          },
          "name": "getTags",
          "doc": "Returns all tags attached to this <code>MediaObject</code>."
        }
      ],
      "events": [
        "Error"
      ]
    },
    {
      "name": "MediaPipeline",
      "doc": "A pipeline is a container for a collection of :rom:cls:`MediaElements<MediaElement>` and :rom:cls:`MediaMixers<MediaMixer>`.\nIt offers the methods needed to control the creation and connection of elements inside a certain pipeline.\n      ",
      "extends": "MediaObject",
      "constructor": {
        "params": [],
        "doc": "Create a :rom:cls:`MediaPipeline`"
      },
      "properties": [
        {
          "name": "latencyStats",
          "doc": "If statistics about pipeline latency are enabled for all mediaElements",
          "type": "boolean"
        }
      ],
      "methods": [
        {
          "params": [
            {
              "name": "details",
              "doc": "Details of graph",
              "type": "GstreamerDotDetails",
              "optional": true
            }
          ],
          "return": {
            "type": "String",
            "doc": "The dot graph."
          },
          "name": "getGstreamerDot",
          "doc": "Returns a string in dot (graphviz) format that represents the gstreamer elements inside the pipeline"
        }
      ]
    },
    {
      "name": "PassThrough",
      "doc": "This :rom:cls:`MediaElement` that just passes media through",
      "extends": "MediaElement",
      "constructor": {
        "params": [
          {
            "name": "mediaPipeline",
            "doc": "the :rom:cls:`MediaPipeline` to which the element belongs",
            "type": "MediaPipeline"
          }
        ],
        "doc": "Builder for the :rom:cls:`PassThrough`"
      }
    },
    {
      "name": "SdpEndpoint",
      "doc": "Interface implemented by Endpoints that require an SDP Offer/Answer negotiation in order to configure a media session.\n<p>Functionality provided by this API:</p>\n<ul>\n  <li>Generate SDP offers.</li>\n  <li>Process SDP offers.</li>\n  <li>Configure SDP related params.</li>\n</ul>\n      ",
      "abstract": true,
      "extends": "SessionEndpoint",
      "properties": [
        {
          "name": "maxAudioRecvBandwidth",
          "doc": "Maximum bitrate expected for the received audio stream.\n<p>\n  This is used to put a limit on the bitrate that the remote peer will send to\n  this endpoint. The net effect of setting this parameter is that\n  <i>when Kurento generates an SDP Offer</i>, an 'Application Specific' (AS)\n  maximum bandwidth attribute will be added to the SDP media section:\n  <code>b=AS:{value}</code>.\n</p>\n<p>Note: This parameter has to be set before the SDP is generated.</p>\n<ul>\n  <li>Unit: kbps (kilobits per second).</li>\n  <li>Default: 0.</li>\n  <li>0 = unconstrained.</li>\n</ul>\n          ",
          "type": "int"
        },
        {
          "name": "maxVideoRecvBandwidth",
          "doc": "Maximum bitrate expected for the received video stream.\n<p>\n  This is used to put a limit on the bitrate that the remote peer will send to\n  this endpoint. The net effect of setting this parameter is that\n  <i>when Kurento generates an SDP Offer</i>, an 'Application Specific' (AS)\n  maximum bandwidth attribute will be added to the SDP media section:\n  <code>b=AS:{value}</code>.\n</p>\n<p>Note: This parameter has to be set before the SDP is generated.</p>\n<ul>\n  <li>Unit: kbps (kilobits per second).</li>\n  <li>Default: 0.</li>\n  <li>0 = unconstrained.</li>\n</ul>\n          ",
          "type": "int"
        }
      ],
      "methods": [
        {
          "params": [
            {
              "name": "options",
              "doc": "An <code>OfferOptions</code> providing options requested for the offer.",
              "type": "OfferOptions",
              "optional": true
            }
          ],
          "return": {
            "type": "String",
            "doc": "The SDP offer."
          },
          "name": "generateOffer",
          "doc": "Generates an SDP offer with media capabilities of the Endpoint.\nThrows:\n<ul>\n  <li>\n    SDP_END_POINT_ALREADY_NEGOTIATED If the endpoint is already negotiated.\n  </li>\n  <li>\n    SDP_END_POINT_GENERATE_OFFER_ERROR if the generated offer is empty. This is\n    most likely due to an internal error.\n  </li>\n</ul>\n          "
        },
        {
          "params": [
            {
              "name": "offer",
              "doc": "SessionSpec offer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "type": "String",
            "doc": "The chosen configuration from the ones stated in the SDP offer."
          },
          "name": "processOffer",
          "doc": "Processes SDP offer of the remote peer, and generates an SDP answer based on the endpoint's capabilities.\n<p>\n  If no matching capabilities are found, the SDP will contain no codecs.\n</p>\nThrows:\n<ul>\n  <li>\n    SDP_PARSE_ERROR If the offer is empty or has errors.\n  </li>\n  <li>\n    SDP_END_POINT_ALREADY_NEGOTIATED If the endpoint is already negotiated.\n  </li>\n  <li>\n    SDP_END_POINT_PROCESS_OFFER_ERROR if the generated offer is empty. This is\n    most likely due to an internal error.\n  </li>\n</ul>\n          "
        },
        {
          "params": [
            {
              "name": "answer",
              "doc": "SessionSpec answer from the remote User Agent",
              "type": "String"
            }
          ],
          "return": {
            "type": "String",
            "doc": "Updated SDP offer, based on the answer received."
          },
          "name": "processAnswer",
          "doc": "Generates an SDP offer with media capabilities of the Endpoint.\nThrows:\n<ul>\n  <li>\n    SDP_PARSE_ERROR If the offer is empty or has errors.\n  </li>\n  <li>\n    SDP_END_POINT_ALREADY_NEGOTIATED If the endpoint is already negotiated.\n  </li>\n  <li>\n    SDP_END_POINT_PROCESS_ANSWER_ERROR if the result of processing the answer is\n    an empty string. This is most likely due to an internal error.\n  </li>\n  <li>\n    SDP_END_POINT_NOT_OFFER_GENERATED If the method is invoked before the\n    generateOffer method.\n  </li>\n</ul>\n          "
        },
        {
          "params": [],
          "return": {
            "type": "String",
            "doc": "The last agreed SessionSpec."
          },
          "name": "getLocalSessionDescriptor",
          "doc": "Returns the local SDP.\n<ul>\n  <li>\n    No offer has been generated: returns null.\n  </li>\n  <li>\n    Offer has been generated: returns the SDP offer.\n  </li>\n  <li>\n    Offer has been generated and answer processed: returns the agreed SDP.\n  </li>\n</ul>\n          "
        },
        {
          "params": [],
          "return": {
            "type": "String",
            "doc": "The last agreed User Agent session description."
          },
          "name": "getRemoteSessionDescriptor",
          "doc": "This method returns the remote SDP.\nIf the negotiation process is not complete, it will return NULL.\n          "
        }
      ]
    },
    {
      "name": "ServerManager",
      "doc": "This is a standalone object for managing the MediaServer",
      "abstract": true,
      "extends": "MediaObject",
      "properties": [
        {
          "name": "info",
          "doc": "Server information, version, modules, factories, etc",
          "type": "ServerInfo",
          "readOnly": true
        },
        {
          "name": "pipelines",
          "doc": "All the pipelines available in the server",
          "type": "MediaPipeline[]",
          "readOnly": true
        },
        {
          "name": "sessions",
          "doc": "All active sessions in the server",
          "type": "String[]",
          "readOnly": true
        },
        {
          "name": "metadata",
          "doc": "Metadata stored in the server",
          "type": "String",
          "readOnly": true
        }
      ],
      "methods": [
        {
          "params": [
            {
              "name": "moduleName",
              "doc": "Name of the module to get its kmd file",
              "type": "String"
            }
          ],
          "return": {
            "type": "String",
            "doc": "The kmd file."
          },
          "name": "getKmd",
          "doc": "Returns the kmd associated to a module"
        },
        {
          "params": [],
          "return": {
            "type": "int",
            "doc": "Number of CPU cores available for the media server."
          },
          "name": "getCpuCount",
          "doc": "Number of CPU cores that the media server can use.\n<p>\n  Linux processes can be configured to use only a subset of the cores that are\n  available in the system, via the process affinity settings\n  (<strong>sched_setaffinity(2)</strong>). With this method it is possible to\n  know the number of cores that the media server can use in the machine where it\n  is running.\n</p>\n<p>\n  For example, it's possible to limit the core affinity inside a Docker\n  container by running with a command such as\n  <em>docker run --cpuset-cpus='0,1'</em>.\n</p>\n<p>\n  Note that the return value represents the number of\n  <em>logical</em> processing units available, i.e. CPU cores including\n  Hyper-Threading.\n</p>\n          "
        },
        {
          "params": [
            {
              "name": "interval",
              "doc": "Time to measure the average CPU usage, in milliseconds.",
              "type": "int"
            }
          ],
          "return": {
            "type": "float",
            "doc": "CPU usage %."
          },
          "name": "getUsedCpu",
          "doc": "Average CPU usage of the server.\n<p>\n  This method measures the average CPU usage of the media server during the\n  requested interval. Normally you will want to choose an interval between 1000\n  and 10000 ms.\n</p>\n<p>\n  The returned value represents the global system CPU usage of the media server,\n  as an average across all processing units (CPU cores).\n</p>\n          "
        },
        {
          "params": [],
          "return": {
            "type": "int64",
            "doc": "Used memory, in KiB."
          },
          "name": "getUsedMemory",
          "doc": "Returns the amount of memory that the server is using, in KiB"
        }
      ],
      "events": [
        "ObjectCreated",
        "ObjectDestroyed"
      ]
    },
    {
      "name": "SessionEndpoint",
      "doc": "All networked Endpoints that require to manage connection sessions with remote peers implement this interface.",
      "abstract": true,
      "extends": "Endpoint",
      "events": [
        "MediaSessionTerminated",
        "MediaSessionStarted"
      ]
    },
    {
      "name": "UriEndpoint",
      "doc": "Interface for endpoints the require a URI to work.\nAn example of this, would be a :rom:cls:`PlayerEndpoint` whose URI property could be used to locate a file to stream.\n      ",
      "abstract": true,
      "extends": "Endpoint",
      "properties": [
        {
          "name": "uri",
          "doc": "The uri for this endpoint.",
          "type": "String",
          "final": true
        },
        {
          "name": "state",
          "doc": "State of the endpoint",
          "type": "UriEndpointState",
          "readOnly": true
        }
      ],
      "methods": [
        {
          "params": [],
          "name": "pause",
          "doc": "Pauses the feed"
        },
        {
          "params": [],
          "name": "stop",
          "doc": "Stops the feed"
        }
      ],
      "events": [
        "UriEndpointStateChanged"
      ]
    }
  ],
  "complexTypes": [
    {
      "typeFormat": "ENUM",
      "values": [
        "STOP",
        "START",
        "PAUSE"
      ],
      "name": "UriEndpointState",
      "doc": "State of the endpoint"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "version",
          "doc": "MediaServer version",
          "type": "String"
        },
        {
          "name": "modules",
          "doc": "Descriptor of all modules loaded by the server",
          "type": "ModuleInfo[]"
        },
        {
          "name": "type",
          "doc": "Describes the type of mediaserver",
          "type": "ServerType"
        },
        {
          "name": "capabilities",
          "doc": "Describes the capabilities that this server supports",
          "type": "String[]"
        }
      ],
      "name": "ServerInfo",
      "doc": "Description of the mediaserver"
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "KMS",
        "KCS"
      ],
      "name": "ServerType",
      "doc": "Indicates if the server is a real media server or a proxy"
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "SHOW_MEDIA_TYPE",
        "SHOW_CAPS_DETAILS",
        "SHOW_NON_DEFAULT_PARAMS",
        "SHOW_STATES",
        "SHOW_FULL_PARAMS",
        "SHOW_ALL",
        "SHOW_VERBOSE"
      ],
      "name": "GstreamerDotDetails",
      "doc": "Details of gstreamer dot graphs"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "version",
          "doc": "Module version",
          "type": "String"
        },
        {
          "name": "name",
          "doc": "Module name",
          "type": "String"
        },
        {
          "name": "generationTime",
          "doc": "Time that this module was generated",
          "type": "String"
        },
        {
          "name": "factories",
          "doc": "Module available factories",
          "type": "String[]"
        }
      ],
      "name": "ModuleInfo",
      "doc": "Description of a loaded modules"
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "DISCONNECTED",
        "CONNECTED"
      ],
      "name": "MediaState",
      "doc": "State of the media."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "FLOWING",
        "NOT_FLOWING"
      ],
      "name": "MediaFlowState",
      "doc": "Flowing state of the media."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "TRANSCODING",
        "NOT_TRANSCODING"
      ],
      "name": "MediaTranscodingState",
      "doc": "Transcoding state for a media."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "DISCONNECTED",
        "CONNECTED"
      ],
      "name": "ConnectionState",
      "doc": "State of the connection."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "AUDIO",
        "DATA",
        "VIDEO"
      ],
      "name": "MediaType",
      "doc": "Type of media stream to be exchanged.\nCan take the values AUDIO, DATA or VIDEO."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "AUDIO",
        "AUTODETECT",
        "VIDEO"
      ],
      "name": "FilterType",
      "doc": "Type of filter to be created.\nCan take the values AUDIO, VIDEO or AUTODETECT."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "VP8",
        "H264",
        "RAW"
      ],
      "name": "VideoCodec",
      "doc": "Codec used for transmission of video."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "OPUS",
        "PCMU",
        "RAW"
      ],
      "name": "AudioCodec",
      "doc": "Codec used for transmission of audio."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "numerator",
          "doc": "the numerator of the fraction",
          "type": "int"
        },
        {
          "name": "denominator",
          "doc": "the denominator of the fraction",
          "type": "int"
        }
      ],
      "name": "Fraction",
      "doc": "Type that represents a fraction of an integer numerator over an integer denominator"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "codec",
          "doc": "Audio codec",
          "type": "AudioCodec"
        },
        {
          "name": "bitrate",
          "doc": "Bitrate",
          "type": "int"
        }
      ],
      "name": "AudioCaps",
      "doc": "Format for audio media"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "codec",
          "doc": "Video codec",
          "type": "VideoCodec"
        },
        {
          "name": "framerate",
          "doc": "Framerate",
          "type": "Fraction"
        }
      ],
      "name": "VideoCaps",
      "doc": "Format for video media"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "source",
          "doc": "The source element in the connection",
          "type": "MediaElement"
        },
        {
          "name": "sink",
          "doc": "The sink element in the connection",
          "type": "MediaElement"
        },
        {
          "name": "type",
          "doc": "MediaType of the connection",
          "type": "MediaType"
        },
        {
          "name": "sourceDescription",
          "doc": "Description of source media. Could be emty.",
          "type": "String"
        },
        {
          "name": "sinkDescription",
          "doc": "Description of sink media. Could be emty.",
          "type": "String"
        }
      ],
      "name": "ElementConnectionData"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "key",
          "doc": "Tag key",
          "type": "String"
        },
        {
          "name": "value",
          "doc": "Tag Value",
          "type": "String"
        }
      ],
      "name": "Tag",
      "doc": "Pair key-value with info about a MediaObject"
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "inboundrtp",
        "outboundrtp",
        "session",
        "datachannel",
        "track",
        "transport",
        "candidatepair",
        "localcandidate",
        "remotecandidate",
        "element",
        "endpoint"
      ],
      "name": "StatsType",
      "doc": "The type of the object."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "name",
          "doc": "The identifier of the media stream",
          "type": "String"
        },
        {
          "name": "type",
          "doc": "Type of media stream",
          "type": "MediaType"
        },
        {
          "name": "avg",
          "doc": "The average time that buffers take to get on the input pad of this element",
          "type": "double"
        }
      ],
      "name": "MediaLatencyStat",
      "doc": "A dictionary that represents the stats gathered."
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "id",
          "doc": "A unique id that is associated with the object that was inspected to produce this Stats object.",
          "type": "String"
        },
        {
          "name": "type",
          "doc": "The type of this object.",
          "type": "StatsType"
        },
        {
          "name": "timestamp",
          "doc": "[DEPRECATED: Use timestampMillis] The timestamp associated with this object: Seconds elapsed since the UNIX Epoch (Jan 1, 1970, UTC).",
          "type": "double"
        },
        {
          "name": "timestampMillis",
          "doc": "The timestamp associated with this event: Milliseconds elapsed since the UNIX Epoch (Jan 1, 1970, UTC).",
          "type": "int64"
        }
      ],
      "name": "Stats",
      "doc": "A dictionary that represents the stats gathered."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "Stats",
      "properties": [
        {
          "name": "inputAudioLatency",
          "doc": "@deprecated\nAudio average measured on the sink pad in nano seconds",
          "type": "double"
        },
        {
          "name": "inputVideoLatency",
          "doc": "@deprecated\nVideo average measured on the sink pad in nano seconds",
          "type": "double"
        },
        {
          "name": "inputLatency",
          "doc": "The average time that buffers take to get on the input pads of this element in nano seconds",
          "type": "MediaLatencyStat[]"
        }
      ],
      "name": "ElementStats",
      "doc": "A dictionary that represents the stats gathered in the media element."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "ElementStats",
      "properties": [
        {
          "name": "audioE2ELatency",
          "doc": "@deprecated\nEnd-to-end audio latency measured in nano seconds",
          "type": "double"
        },
        {
          "name": "videoE2ELatency",
          "doc": "@deprecated\nEnd-to-end video latency measured in nano seconds",
          "type": "double"
        },
        {
          "name": "E2ELatency",
          "doc": "The average end to end latency for each media stream measured in nano seconds",
          "type": "MediaLatencyStat[]"
        }
      ],
      "name": "EndpointStats",
      "doc": "A dictionary that represents the stats gathered in the endpoint element."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "Stats",
      "properties": [],
      "name": "RTCStats",
      "doc": "An RTCStats dictionary represents the stats gathered."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "ssrc",
          "doc": "The synchronized source SSRC",
          "type": "String"
        },
        {
          "name": "associateStatsId",
          "doc": "The associateStatsId is used for looking up the corresponding (local/remote) RTCStats object for a given SSRC.",
          "type": "String"
        },
        {
          "name": "isRemote",
          "doc": "false indicates that the statistics are measured locally, while true indicates that the measurements were done at the remote endpoint and reported in an RTCP RR/XR.",
          "type": "boolean"
        },
        {
          "name": "mediaTrackId",
          "doc": "Track identifier.",
          "type": "String"
        },
        {
          "name": "transportId",
          "doc": "It is a unique identifier that is associated to the object that was inspected to produce the RTCTransportStats associated with this RTP stream.",
          "type": "String"
        },
        {
          "name": "codecId",
          "doc": "The codec identifier",
          "type": "String"
        },
        {
          "name": "firCount",
          "doc": "Count the total number of Full Intra Request (FIR) packets received by the sender. This metric is only valid for video and is sent by receiver.",
          "type": "int64"
        },
        {
          "name": "pliCount",
          "doc": "Count the total number of Packet Loss Indication (PLI) packets received by the sender and is sent by receiver.",
          "type": "int64"
        },
        {
          "name": "nackCount",
          "doc": "Count the total number of Negative ACKnowledgement (NACK) packets received by the sender and is sent by receiver.",
          "type": "int64"
        },
        {
          "name": "sliCount",
          "doc": "Count the total number of Slice Loss Indication (SLI) packets received by the sender. This metric is only valid for video and is sent by receiver.",
          "type": "int64"
        },
        {
          "name": "remb",
          "doc": "The Receiver Estimated Maximum Bitrate (REMB). This metric is only valid for video.",
          "type": "int64"
        },
        {
          "name": "packetsLost",
          "doc": "Total number of RTP packets lost for this SSRC.",
          "type": "int64"
        },
        {
          "name": "fractionLost",
          "doc": "The fraction packet loss reported for this SSRC.",
          "type": "double"
        }
      ],
      "name": "RTCRTPStreamStats",
      "doc": "Statistics for the RTP stream"
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "payloadType",
          "doc": "Payload type as used in RTP encoding.",
          "type": "int64"
        },
        {
          "name": "codec",
          "doc": "e.g., video/vp8 or equivalent.",
          "type": "String"
        },
        {
          "name": "clockRate",
          "doc": "Represents the media sampling rate.",
          "type": "int64"
        },
        {
          "name": "channels",
          "doc": "Use 2 for stereo, missing for most other cases.",
          "type": "int64"
        },
        {
          "name": "parameters",
          "doc": "From the SDP description line.",
          "type": "String"
        }
      ],
      "name": "RTCCodec",
      "doc": "RTC codec statistics"
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCRTPStreamStats",
      "properties": [
        {
          "name": "packetsReceived",
          "doc": "Total number of RTP packets received for this SSRC.",
          "type": "int64"
        },
        {
          "name": "bytesReceived",
          "doc": "Total number of bytes received for this SSRC.",
          "type": "int64"
        },
        {
          "name": "jitter",
          "doc": "Packet Jitter measured in seconds for this SSRC.",
          "type": "double"
        }
      ],
      "name": "RTCInboundRTPStreamStats",
      "doc": "Statistics that represents the measurement metrics for the incoming media stream."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCRTPStreamStats",
      "properties": [
        {
          "name": "packetsSent",
          "doc": "Total number of RTP packets sent for this SSRC.",
          "type": "int64"
        },
        {
          "name": "bytesSent",
          "doc": "Total number of bytes sent for this SSRC.",
          "type": "int64"
        },
        {
          "name": "targetBitrate",
          "doc": "Presently configured bitrate target of this SSRC, in bits per second.",
          "type": "double"
        },
        {
          "name": "roundTripTime",
          "doc": "Estimated round trip time (seconds) for this SSRC based on the RTCP timestamp.",
          "type": "double"
        }
      ],
      "name": "RTCOutboundRTPStreamStats",
      "doc": "Statistics that represents the measurement metrics for the outgoing media stream."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "dataChannelsOpened",
          "doc": "Represents the number of unique datachannels opened.",
          "type": "int64"
        },
        {
          "name": "dataChannelsClosed",
          "doc": "Represents the number of unique datachannels closed.",
          "type": "int64"
        }
      ],
      "name": "RTCPeerConnectionStats",
      "doc": "Statistics related to the peer connection."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "streamIdentifier",
          "doc": "Stream identifier.",
          "type": "String"
        },
        {
          "name": "trackIds",
          "doc": "This is the id of the stats object, not the track.id.",
          "type": "String[]"
        }
      ],
      "name": "RTCMediaStreamStats",
      "doc": "Statistics related to the media stream."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "trackIdentifier",
          "doc": "Represents the track.id property.",
          "type": "String"
        },
        {
          "name": "remoteSource",
          "doc": "true indicates that this is a remote source. false in other case.",
          "type": "boolean"
        },
        {
          "name": "ssrcIds",
          "doc": "Synchronized sources.",
          "type": "String[]"
        },
        {
          "name": "frameWidth",
          "doc": "Only makes sense for video media streams and represents the width of the video frame for this SSRC.",
          "type": "int64"
        },
        {
          "name": "frameHeight",
          "doc": "Only makes sense for video media streams and represents the height of the video frame for this SSRC.",
          "type": "int64"
        },
        {
          "name": "framesPerSecond",
          "doc": "Only valid for video. It represents the nominal FPS value.",
          "type": "double"
        },
        {
          "name": "framesSent",
          "doc": "Only valid for video. It represents the total number of frames sent for this SSRC.",
          "type": "int64"
        },
        {
          "name": "framesReceived",
          "doc": "Only valid for video and when remoteSource is set to true. It represents the total number of frames received for this SSRC.",
          "type": "int64"
        },
        {
          "name": "framesDecoded",
          "doc": "Only valid for video. It represents the total number of frames correctly decoded for this SSRC. ",
          "type": "int64"
        },
        {
          "name": "framesDropped",
          "doc": "Only valid for video. The total number of frames dropped predecode or dropped because the frame missed its display deadline.",
          "type": "int64"
        },
        {
          "name": "framesCorrupted",
          "doc": "Only valid for video. The total number of corrupted frames that have been detected.",
          "type": "int64"
        },
        {
          "name": "audioLevel",
          "doc": "Only valid for audio, and the value is between 0..1 (linear), where 1.0 represents 0 dBov.",
          "type": "double"
        },
        {
          "name": "echoReturnLoss",
          "doc": "Only present on audio tracks sourced from a microphone where echo cancellation is applied. Calculated in decibels.",
          "type": "double"
        },
        {
          "name": "echoReturnLossEnhancement",
          "doc": "Only present on audio tracks sourced from a microphone where echo cancellation is applied.",
          "type": "double"
        }
      ],
      "name": "RTCMediaStreamTrackStats",
      "doc": "Statistics related to the media stream."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "connecting",
        "open",
        "closing",
        "closed"
      ],
      "name": "RTCDataChannelState",
      "doc": "Represents the state of the RTCDataChannel"
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "label",
          "doc": "The RTCDatachannel label.",
          "type": "String"
        },
        {
          "name": "protocol",
          "doc": "The protocol used.",
          "type": "String"
        },
        {
          "name": "datachannelid",
          "doc": "The RTCDatachannel identifier.",
          "type": "int64"
        },
        {
          "name": "state",
          "doc": "The state of the RTCDatachannel.",
          "type": "RTCDataChannelState"
        },
        {
          "name": "messagesSent",
          "doc": "Represents the total number of API 'message' events sent.",
          "type": "int64"
        },
        {
          "name": "bytesSent",
          "doc": "Represents the total number of payload bytes sent on this RTCDatachannel, i.e., not including headers or padding.",
          "type": "int64"
        },
        {
          "name": "messagesReceived",
          "doc": "Represents the total number of API 'message' events received.",
          "type": "int64"
        },
        {
          "name": "bytesReceived",
          "doc": "Represents the total number of bytes received on this RTCDatachannel, i.e., not including headers or padding.",
          "type": "int64"
        }
      ],
      "name": "RTCDataChannelStats",
      "doc": "Statistics related to RTC data channels."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "bytesSent",
          "doc": "Represents the total number of payload bytes sent on this PeerConnection, i.e., not including headers or padding.",
          "type": "int64"
        },
        {
          "name": "bytesReceived",
          "doc": "Represents the total number of bytes received on this PeerConnection, i.e., not including headers or padding.",
          "type": "int64"
        },
        {
          "name": "rtcpTransportStatsId",
          "doc": "If RTP and RTCP are not multiplexed, this is the id of the transport that gives stats for the RTCP component, and this record has only the RTP component stats.",
          "type": "String"
        },
        {
          "name": "activeConnection",
          "doc": "Set to true when transport is active.",
          "type": "boolean"
        },
        {
          "name": "selectedCandidatePairId",
          "doc": "It is a unique identifier that is associated to the object that was inspected to produce the RTCIceCandidatePairStats associated with this transport.",
          "type": "String"
        },
        {
          "name": "localCertificateId",
          "doc": "For components where DTLS is negotiated, give local certificate.",
          "type": "String"
        },
        {
          "name": "remoteCertificateId",
          "doc": "For components where DTLS is negotiated, give remote certificate.",
          "type": "String"
        }
      ],
      "name": "RTCTransportStats",
      "doc": "Statistics related to RTC data channels."
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "host",
        "serverreflexive",
        "peerreflexive",
        "relayed"
      ],
      "name": "RTCStatsIceCandidateType",
      "doc": "Types of candidates"
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "ipAddress",
          "doc": "It is the IP address of the candidate, allowing for IPv4 addresses, IPv6 addresses, and fully qualified domain names (FQDNs).",
          "type": "String"
        },
        {
          "name": "portNumber",
          "doc": "It is the port number of the candidate.",
          "type": "int64"
        },
        {
          "name": "transport",
          "doc": "Valid values for transport is one of udp and tcp. Based on the 'transport' defined in [RFC5245] section 15.1.",
          "type": "String"
        },
        {
          "name": "candidateType",
          "doc": "The enumeration RTCStatsIceCandidateType is based on the cand-type defined in [RFC5245] section 15.1.",
          "type": "RTCStatsIceCandidateType"
        },
        {
          "name": "priority",
          "doc": "Represents the priority of the candidate",
          "type": "int64"
        },
        {
          "name": "addressSourceUrl",
          "doc": "The URL of the TURN or STUN server indicated in the RTCIceServers that translated this IP address.",
          "type": "String"
        }
      ],
      "name": "RTCIceCandidateAttributes",
      "doc": ""
    },
    {
      "typeFormat": "ENUM",
      "values": [
        "frozen",
        "waiting",
        "inprogress",
        "failed",
        "succeeded",
        "cancelled"
      ],
      "name": "RTCStatsIceCandidatePairState",
      "doc": "Represents the state of the checklist for the local and remote candidates in a pair."
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "transportId",
          "doc": "It is a unique identifier that is associated to the object that was inspected to produce the RTCTransportStats associated with this candidate pair.",
          "type": "String"
        },
        {
          "name": "localCandidateId",
          "doc": "It is a unique identifier that is associated to the object that was inspected to produce the RTCIceCandidateAttributes for the local candidate associated with this candidate pair.",
          "type": "String"
        },
        {
          "name": "remoteCandidateId",
          "doc": "It is a unique identifier that is associated to the object that was inspected to produce the RTCIceCandidateAttributes for the remote candidate associated with this candidate pair.",
          "type": "String"
        },
        {
          "name": "state",
          "doc": "Represents the state of the checklist for the local and remote candidates in a pair.",
          "type": "RTCStatsIceCandidatePairState"
        },
        {
          "name": "priority",
          "doc": "Calculated from candidate priorities as defined in [RFC5245] section 5.7.2.",
          "type": "int64"
        },
        {
          "name": "nominated",
          "doc": "Related to updating the nominated flag described in Section 7.1.3.2.4 of [RFC5245].",
          "type": "boolean"
        },
        {
          "name": "writable",
          "doc": "Has gotten ACK to an ICE request.",
          "type": "boolean"
        },
        {
          "name": "readable",
          "doc": "Has gotten a valid incoming ICE request.",
          "type": "boolean"
        },
        {
          "name": "bytesSent",
          "doc": "Represents the total number of payload bytes sent on this candidate pair, i.e., not including headers or padding.",
          "type": "int64"
        },
        {
          "name": "bytesReceived",
          "doc": "Represents the total number of payload bytes received on this candidate pair, i.e., not including headers or padding.",
          "type": "int64"
        },
        {
          "name": "roundTripTime",
          "doc": "Represents the RTT computed by the STUN connectivity checks",
          "type": "double"
        },
        {
          "name": "availableOutgoingBitrate",
          "doc": "Measured in Bits per second, and is implementation dependent. It may be calculated by the underlying congestion control.",
          "type": "double"
        },
        {
          "name": "availableIncomingBitrate",
          "doc": "Measured in Bits per second, and is implementation dependent. It may be calculated by the underlying congestion control.",
          "type": "double"
        }
      ],
      "name": "RTCIceCandidatePairStats",
      "doc": ""
    },
    {
      "typeFormat": "REGISTER",
      "extends": "RTCStats",
      "properties": [
        {
          "name": "fingerprint",
          "doc": "Only use the fingerprint value as defined in Section 5 of [RFC4572].",
          "type": "String"
        },
        {
          "name": "fingerprintAlgorithm",
          "doc": "For instance, 'sha-256'.",
          "type": "String"
        },
        {
          "name": "base64Certificate",
          "doc": "For example, DER-encoded, base-64 representation of a certifiate.",
          "type": "String"
        },
        {
          "name": "issuerCertificateId",
          "doc": "",
          "type": "String"
        }
      ],
      "name": "RTCCertificateStats",
      "doc": ""
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "name",
          "doc": "Name of the codec. Must follow this format: <encoding name>/<clock rate>[/<encoding parameters>]",
          "type": "String",
          "optional": true
        },
        {
          "name": "properties",
          "doc": "String used for tuning codec properties",
          "type": "String<>",
          "optional": true
        }
      ],
      "name": "CodecConfiguration",
      "doc": "Defines specific configuration for codecs"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "packetsRecvIntervalTop",
          "doc": "Size of the RTP packets history to smooth fraction-lost.\nUnits: num of packets",
          "type": "int",
          "optional": true,
          "defaultValue": 100
        },
        {
          "name": "exponentialFactor",
          "doc": "Factor used to increase exponentially the next REMB when it is below the threshold.\nREMB[i+1] = REMB[i] * (1 + exponentialFactor)",
          "type": "float",
          "optional": true,
          "defaultValue": 0.04
        },
        {
          "name": "linealFactorMin",
          "doc": "Set the min of the factor used to increase linearly the next REMB when it is over the threshold.\nUnits: bps (bits per second).\nREMB[i+1] = REMB[i] + MIN (linealFactorMin, linealFactor)",
          "type": "int",
          "optional": true
        },
        {
          "name": "linealFactorGrade",
          "doc": "Determine the value of the next linearFactor based on the threshold and the current REMB. Taking into account that the frequency of updating is 500ms, the default value makes that the last REMB is reached in 60secs.\nlinealFactor = (REMB - TH) / linealFactorGrade",
          "type": "float",
          "optional": true,
          "defaultValue": 30
        },
        {
          "name": "decrementFactor",
          "doc": "Determine how much is decreased the current REMB when too losses are detected.\nREMB[i+1] = REMB[i] * decrementFactor",
          "type": "float",
          "optional": true,
          "defaultValue": 0.5
        },
        {
          "name": "thresholdFactor",
          "doc": "Determine the next threshold (TH) when too losses are detected.\nTH[i+1] = REMB[i] * thresholdFactor",
          "type": "float",
          "optional": true,
          "defaultValue": 0.8
        },
        {
          "name": "upLosses",
          "doc": "Max fraction-lost to no determine too losses. This value is the denominator of the fraction N/256, so the default value is about 4% of losses (12/256)",
          "type": "int",
          "optional": true,
          "defaultValue": 12
        },
        {
          "name": "rembOnConnect",
          "doc": "Initial local REMB bandwidth estimation that gets propagated when a new endpoint is connected.\n<p>\n  The REMB congestion control algorithm works by gradually increasing the output\n  video bitrate, until the available bandwidth is fully used or the maximum send\n  bitrate has been reached. This is a slow, progressive change, which starts at\n  300 kbps by default. You can change the default starting point of REMB\n  estimations, by setting this parameter.\n</p>\n<p>\n  <b>WARNING</b>: If you set this parameter to a high value that is\n  <i>higher than the network capacity</i>, then all endpoints will start already\n  in a congested state, providing very bad video quality until the congestion\n  control algorithm is able to recover from the situation. Network congestion is\n  very unpredictable, so be careful when changing this parameter; for most use\n  cases it is safer to just start with a low initial value and allow the REMB\n  algorithm to raise until the optimum bitrate is reached.\n</p>\n<ul>\n  <li>Unit: bps (bits per second).</li>\n  <li>Default: 300000 (300 kbps).</li>\n</ul>\n          ",
          "type": "int",
          "optional": true,
          "defaultValue": 300000
        }
      ],
      "name": "RembParams",
      "doc": "Defines values for parameters of congestion control"
    },
    {
      "typeFormat": "REGISTER",
      "properties": [
        {
          "name": "offerToReceiveAudio",
          "doc": "Whether or not to offer to the remote peer the opportunity to send audio.",
          "type": "boolean",
          "optional": true,
          "defaultValue": true
        },
        {
          "name": "offerToReceiveVideo",
          "doc": "Whether or not to offer to the remote peer the opportunity to send video.",
          "type": "boolean",
          "optional": true,
          "defaultValue": true
        }
      ],
      "name": "OfferOptions",
      "doc": "Used to customize the offer created by <code>SdpEndpoint.generateOffer</code>."
    }
  ],
  "events": [
    {
      "properties": [
        {
          "name": "source",
          "doc": "Object that raised the event",
          "type": "MediaObject"
        },
        {
          "name": "timestamp",
          "doc": "[DEPRECATED: Use timestampMillis] The timestamp associated with this object: Seconds elapsed since the UNIX Epoch (Jan 1, 1970, UTC).",
          "type": "String"
        },
        {
          "name": "timestampMillis",
          "doc": "The timestamp associated with this event: Milliseconds elapsed since the UNIX Epoch (Jan 1, 1970, UTC).",
          "type": "String"
        },
        {
          "name": "tags",
          "doc": "",
          "type": "Tag[]"
        }
      ],
      "name": "RaiseBase",
      "doc": ""
    },
    {
      "properties": [
        {
          "name": "description",
          "doc": "Textual description of the error",
          "type": "String"
        },
        {
          "name": "errorCode",
          "doc": "Server side integer error code",
          "type": "int"
        },
        {
          "name": "type",
          "doc": "Integer code as a String",
          "type": "String"
        }
      ],
      "extends": "RaiseBase",
      "name": "Error",
      "doc": "Fired whenever an undefined error related to the MediaObject has occurred"
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionTerminated",
      "doc": "Event raised when a session is terminated. This event has no data."
    },
    {
      "properties": [],
      "extends": "Media",
      "name": "MediaSessionStarted",
      "doc": "Event raised when a session starts. This event has no data."
    },
    {
      "properties": [
        {
          "name": "type",
          "doc": "Type of event that was raised",
          "type": "String"
        }
      ],
      "extends": "RaiseBase",
      "name": "Media",
      "doc": "Base for all events raised by elements in the Kurento media server."
    },
    {
      "properties": [
        {
          "name": "object",
          "doc": "The object that has been created",
          "type": "MediaObject"
        }
      ],
      "extends": "RaiseBase",
      "name": "ObjectCreated",
      "doc": "Indicates that an object has been created on the mediaserver"
    },
    {
      "properties": [
        {
          "name": "objectId",
          "doc": "The id of the object that has been destroyed",
          "type": "String"
        }
      ],
      "extends": "RaiseBase",
      "name": "ObjectDestroyed",
      "doc": "Indicates that an object has been destroyed on the mediaserver"
    },
    {
      "properties": [
        {
          "name": "oldState",
          "doc": "The previous state",
          "type": "MediaState"
        },
        {
          "name": "newState",
          "doc": "The new state",
          "type": "MediaState"
        }
      ],
      "extends": "Media",
      "name": "MediaStateChanged",
      "doc": "This event is fired when the media connection between two peers changes, based on the RTCP packet flow. It contains the old and the new state. Possible values are\n      <ul>\n        <li>CONNECTED</li>\n        <li>DISCONNECTED</li>\n      </ul>"
    },
    {
      "properties": [
        {
          "name": "oldState",
          "doc": "The previous state",
          "type": "ConnectionState"
        },
        {
          "name": "newState",
          "doc": "The new state",
          "type": "ConnectionState"
        }
      ],
      "extends": "Media",
      "name": "ConnectionStateChanged",
      "doc": "This event is raised when the connection between two peers changes. It contains the old and the new state. Possible values are\n      <ul>\n        <li>CONNECTED</li>\n        <li>DISCONNECTED</li>\n      </ul>"
    },
    {
      "properties": [
        {
          "name": "state",
          "doc": "Current media state",
          "type": "MediaFlowState"
        },
        {
          "name": "padName",
          "doc": "Name of the pad which has media",
          "type": "String"
        },
        {
          "name": "mediaType",
          "doc": "Type of media that is flowing",
          "type": "MediaType"
        }
      ],
      "extends": "Media",
      "name": "MediaFlowOutStateChange",
      "doc": "Fired when the outgoing media flow begins or ends. The event contains:\n      <ul>\n        <li>State: whether the endpoint is sending media (FLOWING) or not (NOT_FLOWING).</li>\n        <li>padName. The name of the pad that changed state.</li>\n        <li>MediaType: The type of media flowing.</li>\n      </ul>"
    },
    {
      "properties": [
        {
          "name": "state",
          "doc": "Current media state",
          "type": "MediaFlowState"
        },
        {
          "name": "padName",
          "doc": "Name of the pad which has media",
          "type": "String"
        },
        {
          "name": "mediaType",
          "doc": "Type of media that is flowing",
          "type": "MediaType"
        }
      ],
      "extends": "Media",
      "name": "MediaFlowInStateChange",
      "doc": "Fired when the incoming media flow begins or ends. The event contains:\n      <ul>\n        <li>State: whether the endpoint is receiving media (FLOWING) or not (NOT_FLOWING).</li>\n        <li>padName. The name of the pad that changed state.</li>\n        <li>MediaType: The type of media flowing.</li>\n      </ul>"
    },
    {
      "properties": [
        {
          "name": "state",
          "doc": "Current transcoding state; either enabled or disabled.",
          "type": "MediaTranscodingState"
        },
        {
          "name": "binName",
          "doc": "Name of the GStreamer bin which is processing the media.",
          "type": "String"
        },
        {
          "name": "mediaType",
          "doc": "Type of media that is being processed; either audio or video.",
          "type": "MediaType"
        }
      ],
      "extends": "Media",
      "name": "MediaTranscodingStateChange",
      "doc": "Event fired when an incoming media begins and codec transcoding is either required or not."
    },
    {
      "properties": [
        {
          "name": "sink",
          "doc": "sink element in new connection",
          "type": "MediaElement"
        },
        {
          "name": "mediaType",
          "doc": "Media type of the connection",
          "type": "MediaType"
        },
        {
          "name": "sourceMediaDescription",
          "doc": "Description of the source media",
          "type": "String"
        },
        {
          "name": "sinkMediaDescription",
          "doc": "Description of the sink media",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "ElementConnected",
      "doc": "Indicates that an element has been connected to another"
    },
    {
      "properties": [
        {
          "name": "sink",
          "doc": "sink element in previous connection",
          "type": "MediaElement"
        },
        {
          "name": "mediaType",
          "doc": "Media type of the previous connection",
          "type": "MediaType"
        },
        {
          "name": "sourceMediaDescription",
          "doc": "Description of the source media",
          "type": "String"
        },
        {
          "name": "sinkMediaDescription",
          "doc": "Description of the sink media",
          "type": "String"
        }
      ],
      "extends": "Media",
      "name": "ElementDisconnected",
      "doc": "Indicates that an element has been disconnected from another"
    },
    {
      "properties": [
        {
          "name": "state",
          "doc": "the new state",
          "type": "UriEndpointState"
        }
      ],
      "extends": "Media",
      "name": "UriEndpointStateChanged",
      "doc": "Indicates the new state of the endpoint"
    }
  ]
}
